{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24d43f23-5000-4499-9a27-ea231ffe74e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TRAIN ON TRAIN_B, PREDICT ON TEST_B\n",
      "==================================================\n",
      "Engineering features...\n",
      "Building base pipeline...\n",
      "Starting hyperparameter tuning...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "Best parameters:\n",
      "{'model__l2_regularization': 1.0, 'model__learning_rate': 0.02, 'model__max_depth': 5, 'model__max_iter': 300, 'model__min_samples_leaf': 5}\n",
      "Best CV Macro F1: 0.5596\n",
      "Saved predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. FEATURE ENGINEERING\n",
    "\n",
    "def engineer_features(X):\n",
    "    X_new = X.copy()\n",
    "    \n",
    "    for col in X_new.columns:\n",
    "        if X_new[col].isnull().sum() > 0:\n",
    "            X_new[f'{col}_missing'] = X_new[col].isnull().astype(int)\n",
    "    \n",
    "    X_f = X_new.fillna(X_new.median(numeric_only=True)).fillna('unknown')\n",
    "    \n",
    "    X_new['engagement_score'] = X_f['sessions_per_week'] * X_f['avg_session_duration_min'] * (X_f['features_used_pct']/100)\n",
    "    X_new['recency'] = 1 / (X_f['days_since_last_login'] + 1)\n",
    "    X_new['support_pain'] = X_f['num_support_tickets_90d'] * (1 + X_f['unresolved_tickets']) / X_f['avg_ticket_resolution_hrs'].replace(0, 1)\n",
    "    X_new['stability'] = 1 / (X_f['app_crash_count_30d'] + 1)\n",
    "    X_new['value_ratio'] = X_f['subscription_duration_days'] / (X_f['monthly_price_inr'] + 1)\n",
    "    X_new['price_sens'] = ((X_f['monthly_price_inr'] > X_f['monthly_price_inr'].median()).astype(int) *\n",
    "                           (X_f['sessions_per_week'] < X_f['sessions_per_week'].median()).astype(int))\n",
    "    X_new['tech_issues'] = (X_f['app_crash_count_30d'] > 0).astype(int) + (X_f['num_support_tickets_90d'] > 0).astype(int)\n",
    "    X_new['competitor_risk'] = X_f['competitor_app_installed'].astype(int) * 2 + (~X_f['notification_opt_in']).astype(int)\n",
    "    \n",
    "    for col in X_new.select_dtypes([np.number]).columns:\n",
    "        if X_new[col].min() >= 0 and abs(X_new[col].skew()) > 1.0:\n",
    "            X_new[col + '_log'] = np.log1p(X_new[col])\n",
    "    \n",
    "    return X_new\n",
    "\n",
    "# 2. PIPELINE\n",
    "\n",
    "def build_base_pipeline():\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', Pipeline([\n",
    "            ('impute', SimpleImputer(strategy='median')),\n",
    "            ('scale', StandardScaler())\n",
    "        ]), lambda X: X.select_dtypes(include='number').columns),\n",
    "        \n",
    "        ('cat', Pipeline([\n",
    "            ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "            ('encode', OneHotEncoder(drop='if_binary', handle_unknown='ignore', sparse_output=False))\n",
    "        ]), lambda X: X.select_dtypes(exclude='number').columns)\n",
    "    ])\n",
    "    \n",
    "    model = HistGradientBoostingClassifier(random_state=42)\n",
    "    \n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "# MAIN EXECUTION\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"TRAIN ON TRAIN_B, PREDICT ON TEST_B\")\n",
    "\n",
    "    \n",
    "    train_df = pd.read_csv('train_B.csv')\n",
    "    test_df = pd.read_csv('test_B.csv')\n",
    "    \n",
    "    X_train = train_df.drop(columns=['churn_reason', 'id'])\n",
    "    y = train_df['churn_reason']\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "    \n",
    "    print(\"Engineering features...\")\n",
    "    X_train_eng = engineer_features(X_train)\n",
    "    X_test_eng = engineer_features(test_df.drop(columns=['id']))\n",
    "\n",
    "    # ---- FIX: align test columns to train columns ----\n",
    "    missing_cols = set(X_train_eng.columns) - set(X_test_eng.columns)\n",
    "    for col in missing_cols:\n",
    "        X_test_eng[col] = 0\n",
    "\n",
    "    extra_cols = set(X_test_eng.columns) - set(X_train_eng.columns)\n",
    "    X_test_eng = X_test_eng.drop(columns=extra_cols)\n",
    "\n",
    "    X_test_eng = X_test_eng[X_train_eng.columns]\n",
    "    \n",
    "    print(\"Building base pipeline...\")\n",
    "    base_pipeline = build_base_pipeline()\n",
    "    \n",
    "    param_grid = {\n",
    "        'model__max_iter': [300, 500],\n",
    "        'model__learning_rate': [0.02, 0.05],\n",
    "        'model__max_depth': [5, 7],\n",
    "        'model__min_samples_leaf': [5, 10],\n",
    "        'model__l2_regularization': [0.0, 0.5, 1.0]\n",
    "    }\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(\n",
    "        base_pipeline,\n",
    "        param_grid,\n",
    "        cv=cv,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"Starting hyperparameter tuning...\")\n",
    "    grid_search.fit(X_train_eng, y_enc)\n",
    "    \n",
    "    print(\"\\nBest parameters:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(f\"Best CV Macro F1: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    preds_enc = best_model.predict(X_test_eng)\n",
    "    preds = le.inverse_transform(preds_enc)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': test_df['id'],\n",
    "        'prediction': preds\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('predictions.csv', index=False)\n",
    "    print(\"Saved predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c939c2b0-c248-4664-9bde-4abbcdfe5a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d508e42-8446-4d11-9b89-bd10f584af5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8129fd-96de-4fec-b9cd-126ddb2b95c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
